{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKhrA7fQ2oS6",
    "outputId": "55bc4934-0cd5-4cd3-aec9-6892289a6a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEkG_SvV2sGw",
    "outputId": "9e370adc-1d7b-4110-b6c1-e9a1df34955a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/hj/nlp\n"
     ]
    }
   ],
   "source": [
    "cd \"/content/drive/MyDrive/hj/nlp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXrCH4B83DQi",
    "outputId": "fda73cbe-afd4-448d-e92c-4f2cdd29f863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-pretrained-bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 19.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.40-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 66.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.13.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n",
      "Collecting botocore<1.30.0,>=1.29.40\n",
      "  Downloading botocore-1.29.40-py3-none-any.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 60.7 MB/s \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.40->boto3->pytorch-pretrained-bert) (2.8.2)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 69.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.40->boto3->pytorch-pretrained-bert) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 70.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed boto3-1.26.40 botocore-1.29.40 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting zstandard\n",
      "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 11.9 MB/s \n",
      "\u001b[?25hInstalling collected packages: zstandard\n",
      "Successfully installed zstandard-0.19.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "Building wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9307 sha256=e08108c15a47807fc785e42f6e2e2e9d0a6a4c0521ebe65c696e40b8796a36bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/62/8b/71813348245ae1bcbae179193bbc72db819e8057e89298a6ac\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext\n",
      "Successfully installed flashtext-2.7\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 13.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 72.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 54.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert\n",
    "!pip install zstandard\n",
    "!pip install flashtext\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W16umwr-7ICq"
   },
   "source": [
    "## git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdfJWrHV7JmJ",
    "outputId": "cf7a3704-b71d-46b9-9655-2e9ab211bda0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DialoGPT'...\n",
      "remote: Enumerating objects: 344, done.\u001b[K\n",
      "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
      "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
      "remote: Total 344 (delta 131), reused 132 (delta 125), pack-reused 169\u001b[K\n",
      "Receiving objects: 100% (344/344), 44.82 MiB | 14.03 MiB/s, done.\n",
      "Resolving deltas: 100% (160/160), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/microsoft/DialoGPT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHjFY8EY7e_d",
    "outputId": "daa70a96-4385-41a7-affa-210c3ba46183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DialoGPT2-Interact'...\n",
      "remote: Enumerating objects: 15, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 15 (delta 2), reused 3 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (15/15), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/andreamad8/DialoGPT2-Interact.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKXgx12W7sSJ",
    "outputId": "a0c3d068-5f4f-4b58-88a4-5a3236293b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/hj/nlp/DialoGPT\n"
     ]
    }
   ],
   "source": [
    "cd DialoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSucNUVWr_tx"
   },
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HefKv4IQ7unW",
    "outputId": "54cbe9aa-b7eb-47a2-86ac-112bfc98d437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"interact.py\", line 7, in <module>\n",
      "    import torch\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/__init__.py\", line 649, in <module>\n",
      "    from ._tensor import Tensor\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 21, in <module>\n",
      "    from torch.overrides import (\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/overrides.py\", line 54, in <module>\n",
      "    def get_ignored_functions() -> Set[Callable]:\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 258, in inner\n",
      "    return cached(*args, **kwds)\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 687, in __getitem__\n",
      "    return _subs_tvars(self, self.__parameters__, params)\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 203, in _subs_tvars\n",
      "    return tp.copy_with(tuple(new_args))\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 691, in copy_with\n",
      "    return _GenericAlias(self.__origin__, params, name=self._name, inst=self._inst)\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 669, in __init__\n",
      "    self.__args__ = tuple(... if a is _TypingEllipsis else\n",
      "  File \"/usr/lib/python3.8/typing.py\", line 762, in __setattr__\n",
      "    def __setattr__(self, attr, val):\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python interact.py --model_name_or_path ./models/medium --load_checkpoint ./models/medium/medium_ft.pkl --top_k 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXMcJX-T5nUi",
    "outputId": "0b4912b5-ad62-4549-8a3e-13052fa7f186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_FOLDER = /content/drive/MyDrive/hj/nlp/DialoGPT\n",
      "Found existing models folder at /content/drive/MyDrive/hj/nlp/DialoGPT/models, skip creating a new one!\n",
      "12/28/2022 18:02:52 - INFO - __main__ -   Downloading models...\n",
      "100% 176/176 [00:00<00:00, 187074.89B/s]\n",
      "100% 1042301/1042301 [00:01<00:00, 571830.22B/s]\n",
      "100% 456318/456318 [00:01<00:00, 323244.65B/s]\n",
      "100% 548118077/548118077 [01:47<00:00, 5101282.44B/s]\n",
      "100% 351265273/351265273 [01:31<00:00, 3851744.56B/s]\n",
      "12/28/2022 18:06:18 - INFO - __main__ -   Done!\n",
      "\n",
      "12/28/2022 18:06:18 - INFO - __main__ -   Downloading and Extracting Data...\n",
      "12/28/2022 18:24:03 - INFO - __main__ -   Preparing Data...\n",
      "prepro.py --corpus /content/drive/MyDrive/hj/nlp/DialoGPT/data/train.tsv --max_seq_len 128\n",
      "12/28/2022 18:28:31 - INFO - __main__ -   Done!\n",
      "\n",
      "12/28/2022 18:28:31 - INFO - __main__ -   Generating training CMD!\n",
      "12/28/2022 18:28:31 - INFO - __main__ -   If there is any problem, please copy (modify) and run command below\n",
      "12/28/2022 18:28:31 - INFO - __main__ -   #########################################################################\n",
      "python LSP_train.py --model_name_or_path /content/drive/MyDrive/hj/nlp/DialoGPT/models/small --init_checkpoint /content/drive/MyDrive/hj/nlp/DialoGPT/models/small/pytorch_model.bin --train_input_file /content/drive/MyDrive/hj/nlp/DialoGPT/data/train.128len.db --eval_input_file ./data/dummy_data.tsv --output_dir /content/drive/MyDrive/hj/nlp/DialoGPT/models/output_model --seed 42 --max_seq_length 128 --train_batch_size 512 --gradient_accumulation_steps 8 --eval_batch_size 64 --learning_rate 1e-5 --num_optim_steps 10000 --valid_step 5000 --warmup_steps 4000 --normalize_data true --fp16 true --lr_schedule noam --loss_scale 0.0 --no_token_id true --pbar true\n",
      "12/28/2022 18:28:31 - INFO - __main__ -   #########################################################################\n",
      "12/28/2022 18:28:33 - INFO - __main__ -   train batch size = 512, new train batch size (after gradient accumulation) = 64\n",
      "12/28/2022 18:28:33 - INFO - __main__ -   CUDA available? True\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   Input Argument Information\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   model_name_or_path            /content/drive/MyDrive/hj/nlp/DialoGPT/models/small\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   seed                          42\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   max_seq_length                128\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   skip_eval                     False\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   init_checkpoint               /content/drive/MyDrive/hj/nlp/DialoGPT/models/small/pytorch_model.bin\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   train_input_file              /content/drive/MyDrive/hj/nlp/DialoGPT/data/train.128len.db\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   eval_input_file               ./data/dummy_data.tsv\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   continue_from                 0\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   train_batch_size              64\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   gradient_accumulation_steps   8\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   eval_batch_size               64\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   learning_rate                 1e-05\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   num_optim_steps               10000\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   valid_step                    5000\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   warmup_proportion             0.1\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   warmup_steps                  4000\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   normalize_data                True\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   fp16                          True\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   lr_schedule                   noam\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   loss_scale                    0.0\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   no_token_id                   True\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   output_dir                    /content/drive/MyDrive/hj/nlp/DialoGPT/models/output_model\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   log_dir                       None\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   pbar                          True\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   local_rank                    -1\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   config                        None\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   device                        cuda\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   n_gpu                         1\n",
      "12/28/2022 18:28:34 - ERROR - pytorch_pretrained_bert.tokenization_gpt2 -   Model name '/content/drive/MyDrive/hj/nlp/DialoGPT/models/small' was not found in model name list (gpt2). We assumed '/content/drive/MyDrive/hj/nlp/DialoGPT/models/small' was a path or url but couldn't find files /content/drive/MyDrive/hj/nlp/DialoGPT/models/small/vocab.json and /content/drive/MyDrive/hj/nlp/DialoGPT/models/small/merges.txt at this path or url.\n",
      "Traceback (most recent call last):\n",
      "  File \"LSP_train.py\", line 170, in <module>\n",
      "    config = GPT2Config.from_json_file(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_pretrained_bert/modeling_gpt2.py\", line 164, in from_json_file\n",
      "    with open(json_file, \"r\", encoding=\"utf-8\") as reader:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/hj/nlp/DialoGPT/models/small/config.json'\n",
      "12/28/2022 18:28:34 - INFO - __main__ -   Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python demo.py --data small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrkQA7KZ-DOh"
   },
   "source": [
    "## 패키지 준비\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uv3JkjgU2hGi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import abspath, dirname, exists, join\n",
    "import argparse\n",
    "import logging\n",
    "from tqdm import trange\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import socket\n",
    "import os, sys\n",
    "import re\n",
    "import logging\n",
    "from functools import partial\n",
    "#from demo_utils import download_model_folder\n",
    "import argparse\n",
    "import subprocess as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import BucketingDataLoader, DynamicBatchingLoader, DistributedBucketingDataLoader\n",
    "#from pytorch_pretrained_bert import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, BertForSequenceClassification, BertConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from gpt2_training.train_utils import get_eval_list_same_length, load_model, boolean_string, fix_state_dict_namespace\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "EOS_ID = 50256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvPxMsIx-MjN"
   },
   "source": [
    "## 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s0uwhlMI-OiR"
   },
   "outputs": [],
   "source": [
    "def cut_seq_to_eos(sentence, remove_id=[-1]):\n",
    "    sent=[]\n",
    "    for s in sentence:\n",
    "        if s in remove_id:\n",
    "            continue\n",
    "        if s != EOS_ID:\n",
    "            sent.append(s)\n",
    "        else:\n",
    "            break\n",
    "    return sent\n",
    "\n",
    "\n",
    "### FROM HUGGING FACE REPO\n",
    "def top_filtering(logits, top_k=0, top_p=0.0, threshold=-float('Inf'), filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k, top-p (nucleus) and/or threshold filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k: <=0: no filtering, >0: keep only top k tokens with highest probability.\n",
    "            top_p: <=0.0: no filtering, >0.0: keep only a subset S of candidates, where S is the smallest subset\n",
    "                whose total probability mass is greater than or equal to the threshold top_p.\n",
    "                In practice, we select the highest probability tokens whose cumulative probability mass exceeds\n",
    "                the threshold top_p.\n",
    "            threshold: a minimal threshold to keep logits\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # Only work for batch size 1 for now - could update but it would obfuscate a bit the code\n",
    "    top_k = min(top_k, logits.size(-1))\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token in the top-k tokens\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        # Compute cumulative probabilities of sorted tokens\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probabilities = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probabilities > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        # Back to unsorted indices and set them to -infinity\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    indices_to_remove = logits < threshold\n",
    "    logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "def generate_next_token(model, input_ids, position_ids=None, token_type_ids=None, prev=None, temperature=1, top_k=0, top_p=0, past=None):\n",
    "    with torch.no_grad():\n",
    "        if not past:\n",
    "            hidden_states, past = model.transformer(prev, position_ids, token_type_ids, past)\n",
    "        else:\n",
    "            hidden_states, past = model.transformer(prev, past=past)\n",
    "        logits = model.lm_head(hidden_states)\n",
    "        logits = logits[0, -1, :] / temperature\n",
    "        logits = top_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "        probs = F.softmax(logits.unsqueeze(0), dim=-1)\n",
    "        prev = torch.multinomial(probs, num_samples=1)\n",
    "        return prev, probs[0][prev], past\n",
    "\n",
    "def generate_sequence(model, input_ids, position_ids=None, token_type_ids=None, temperature=1, top_k=0, top_p=0, length=20, past=None, device='cuda'):\n",
    "    output = input_ids.new_zeros([input_ids.size(0),0])\n",
    "    prev = input_ids\n",
    "    for i in range(length):\n",
    "        prev, probs, past = generate_next_token(model, input_ids, position_ids, token_type_ids, prev, temperature, top_k, top_p, past)\n",
    "        output = torch.cat((output, prev), dim=1)\n",
    "    return output\n",
    "\n",
    "def cut_seq_to_eos(sentence, remove_id=[-1]):\n",
    "    sent=[]\n",
    "    for s in sentence:\n",
    "        if s in remove_id:\n",
    "            continue\n",
    "        if s != EOS_ID:\n",
    "            sent.append(s)\n",
    "        else:\n",
    "            break\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpHIKZMj-RJh"
   },
   "source": [
    "## 데이터에 대해 응답 생성, 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "91f38a84fcd74cde9b0089fec28a8c0d",
      "2702c4867d7b439b92c0eedae122ddf8",
      "9492632cbac54938a9a833dcf7245919",
      "c41a460b32464439986ceff8c56c226e",
      "a3f1d255d33f45aab0e65b0c7ce31b7b",
      "7cb312662ec4445bb9ac3e51af6af70c",
      "da4e4ca6d09d427a9fe7ef93756e3bc9",
      "d8e139c2e3254dc7a2478555a60600d6",
      "694ca3557bce4cb9abd3494df5e3fccd",
      "99bafd08439d41d6ac192045d1f31fd8",
      "f7c8ebd9eacd486d98b78678d0b6618c",
      "c8ef5390aaf9477d9e7194e1d5365e2f",
      "d975e3a953eb4aea837e9f45d3535ac7",
      "2b0e99810686444292a9d433123427d0",
      "0825bb79bb4e4a3ca6fc262d85115698",
      "02f1d7778a3b4c6b935e6894ecbb286a",
      "c92bb8b9d5aa4aeaac2950cb9ccf73ff",
      "54e65fa9345d405a839e6e99af6f51d8",
      "6f1173e1260440799d72e849ac0d2500",
      "472c0527457b42aa94909ce527034ba7",
      "87adac30280342f7a8d1352f12c316f7",
      "29bd60600a6f45bf877659726b6a45a5",
      "83e856a3a02641a09c4627b3e59e3128",
      "2194c574fd35495bbed06e82b1a013ce",
      "09db7d7a73124f01a16ec74e2d682a43",
      "3a5808be83d742aab60a2b259865238e",
      "38945aa937fa41ab81161ed6c2ee30ea",
      "0d01351ba01a48b0b37f7ab574d8c6d8",
      "188e723f8e1a4ebdbe0d279db0ae90f1",
      "c4a00089edd7418698ecae796839d5b8",
      "1b1423dbce724d83b0a0284b965f9b59",
      "1e15765b8bc540f3873b11ce25cec251",
      "f782225cde864538b319872c54da8796",
      "97185e23041048ed89ef72155ef96994",
      "ca0ac0dc040543edb8b8337ffa81cebc",
      "1ade84462c704497a9cb7851b4469ac2",
      "6ea59210ee5d400a9b0828a62903c143",
      "a950f1757afa422f9128abcc885c82d5",
      "2292aa36157348f792951a5b55a0db73",
      "34749134936c4747903244810dfb88cd",
      "6771f58c7e864c9082c508e63b6bd95f",
      "b05cfbc37b4f440f910ec62ee3289d77",
      "2bceafb970d54462b2688147f59ebbc5",
      "31d0feb2c9dd4e5e9b3ee82db3b97590",
      "5273c39161b646878eb5a3efc39afc44",
      "a6c6aa95f1af40a68325bac7b21b0aea",
      "f830d977c85144be9be2c831fa45f928",
      "ce8bb417e4334b94ba3f873ee57878a6",
      "9f2ffe81371c411883a82928ff24c673",
      "21aa0ea9e1cd4579aaeb1db66c55e323",
      "135d56637ce94f56b92133d59cc8f4f9",
      "47c04e98be0a4c5a8a384364d75f21da",
      "32b8245357c44077be92bf0bf234d100",
      "0c54771fb9f04b218f5ea1e772b11191",
      "7115aa1a40c042b4a210707c339b067c"
     ]
    },
    "id": "1OOI3kAx-TE_",
    "outputId": "a2855d87-dcce-435f-df05-b1895bdf0e7b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f38a84fcd74cde9b0089fec28a8c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ef5390aaf9477d9e7194e1d5365e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e856a3a02641a09c4627b3e59e3128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97185e23041048ed89ef72155ef96994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5273c39161b646878eb5a3efc39afc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name_or_path', type=str, default='./models/medium', help='pretrained model name or path to local checkpoint')\n",
    "parser.add_argument(\"--seed\", type=int, default=42)\n",
    "parser.add_argument(\"--load_checkpoint\", '-c', type=str, default='./models/medium/medium_ft.pkl')\n",
    "parser.add_argument(\"--fp16\", type=boolean_string, default=False)\n",
    "parser.add_argument(\"--max_seq_length\", type=int, default=128)\n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=1,\n",
    "                    help=\"batch size now means per GPU per step\")\n",
    "parser.add_argument(\"--train_input_file\", type=str, default='./data/train.128len.db')\n",
    "    \n",
    "parser.add_argument(\"--generation_length\", type=int, default=20)\n",
    "parser.add_argument(\"--max_history\", type=int, default=2)\n",
    "\n",
    "parser.add_argument(\"--temperature\", type=float, default=1)\n",
    "parser.add_argument(\"--top_k\", type=int, default=10)\n",
    "parser.add_argument(\"--top_p\", type=float, default=0.9)\n",
    "\n",
    "parser.add_argument('--use_gpu', action='store_true')\n",
    "parser.add_argument(\"--gpu\", type=int, default=0)\n",
    "parser.add_argument(\"-f\", type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "args.device, args.n_gpu = device, n_gpu\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.random.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "#### load the GPT-2 model \n",
    "#config = GPT2Config.from_json_file(os.path.join(args.model_name_or_path, 'config.json'))\n",
    "#enc = GPT2Tokenizer.from_pretrained(args.model_name_or_path)\n",
    "#model = load_model(GPT2LMHeadModel(config), args.load_checkpoint, args, verbose=True)\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    "enc = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "#########################################################################\n",
    "# Prepare Data Set\n",
    "##########################################################################\n",
    "\n",
    "train_dataloader = BucketingDataLoader(args.train_input_file,\n",
    "                                        args.train_batch_size,\n",
    "                                        args.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_X6njan-UQe",
    "outputId": "aedd3806-c46b-49ab-970e-f9374f59deb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  Can it go negative?\n",
      "Output1 :  It can't go negative.\n",
      "Output2 :  It can go negative, but it can't go negative.\n",
      "Output3 :  It can go negative, but it can't go positive.\n",
      "Output4 :  It can go negative, but it won't go negative.\n",
      "Output5 :  No, but it can go positive.\n",
      "Label :  If it does, will it signify that people also disapprove of the job he's not doing?\n",
      "\n",
      "\n",
      "Input :  It's high comedy! A morbidly obese man making a documentary about health care? C'mon! Laugh along.\n",
      "Output1 :  It's high comedy! A morbidly obese man making a documentary about health care? C'mon! Laugh along.\n",
      "Output2 :  It's high comedy! A morbidly obese man making a documentary about health care? C'mon! Laugh along. english haiku bot\n",
      "Output3 :  It's high comedy! A morbidly obese man making a documentary about health care? C'mon! Laugh along. FTFY\n",
      "Output4 :  It's high comedy! A morbidly obese man making a documentary about health care? C'mon! laugh along.\n",
      "Output5 :  I laughed.\n",
      "Label :  he actually lost a lot of weight because of the things he learned doing the doc.\n",
      "\n",
      "\n",
      "Input :  Again, I use Google Apps for the email to all of my domains now, so it's unavoidable.\n",
      "Output1 :  I use Google Apps for the email to all of my domains now, so it's unavoidable. english haiku bot\n",
      "Output2 :  I use Google Apps for the email to all of my domains now, so It's unavoidable. amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp\n",
      "Output3 :  I use Google Apps for the email to all of my domains now, so It's unavoidable. amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp\n",
      "Output4 :  I use Google Apps for the email to all of my domains now, so it's unavoidable.\n",
      "Output5 :  I use Google Apps for the email to all of my domains now, so It's unavoidable. amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp amp nbsp\n",
      "Label :  I do believe dmilor was backing you up.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "model.eval()\n",
    "for batch in train_dataloader:\n",
    "    if i==3:\n",
    "        break\n",
    "    #print(input_ids.shape, position_ids.shape, token_ids.shape, label_ids.shape)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
    "    input_ids = input_ids[0].reshape(1, -1)\n",
    "    label_ids = label_ids[0].reshape(1, -1)\n",
    "    \n",
    "    input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device)\n",
    "\n",
    "    out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, num_beams=5, num_return_sequences=5)\n",
    "    \n",
    "    input_ids = input_ids[0][:-1]\n",
    "    label_ids = label_ids[label_ids!=-1][:-1].tolist()\n",
    "    label_ids = cut_seq_to_eos(label_ids)\n",
    "\n",
    "    print(\"Input : \", enc.decode(input_ids))\n",
    "    for j in range(5):\n",
    "        output = out[j]\n",
    "        output = output[output!=-1][input_ids.size(-1)+1:-1]\n",
    "        print(\"Output{} : \".format(j+1), enc.decode(output))\n",
    "    print(\"Label : \", enc.decode(label_ids))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5krL_UXxXSHl"
   },
   "source": [
    "## Discriminator 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X8W6ASC6XU_A"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.num_layers = 10\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=512, num_layers=self.num_layers, batch_first=True, bidirectional=True, dropout=0.3)\n",
    "        self.fc1 = nn.Linear(512*2*self.num_layers, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        h0 = torch.zeros((2*self.num_layers, batch_size, 512)).to(device)\n",
    "        c0 = torch.zeros((2*self.num_layers, batch_size, 512)).to(device)\n",
    "        input = input.reshape(batch_size, -1, 1).float()\n",
    "        _, (h, c) = self.lstm(input, (h0, c0))\n",
    "        h = h.reshape(batch_size, 1024*self.num_layers)\n",
    "        output = self.leakyrelu(self.fc1(self.leakyrelu(h)))\n",
    "        output = self.sigmoid(self.fc2(output))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIDAhvJXH5ho",
    "outputId": "9754080c-bda1-48ad-9a4c-c242fa42dc4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "D = Discriminator().to(device)\n",
    "#D = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(D.parameters(), lr=0.001)\n",
    "\n",
    "D.load_state_dict(torch.load('D_lstm10_fc2.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OdMCvGz0R6l"
   },
   "source": [
    "## 작은 데이터셋 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26ggPJqV0YQ6",
    "outputId": "ca59b6a6-2e8f-45d4-e3a1-ddd4614cc701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = 10000\n",
    "num_test_samples = 1000\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i < num_train_samples:\n",
    "        train_dataset.append(batch)\n",
    "    if i >= num_train_samples and i < num_train_samples+num_test_samples:\n",
    "        test_dataset.append(batch)\n",
    "    if i == num_train_samples+num_test_samples:\n",
    "        break\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM-W8upmgc7w"
   },
   "source": [
    "## Discriminator 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7Svhk_IZJYP"
   },
   "outputs": [],
   "source": [
    "out_real = []\n",
    "out_fake = []\n",
    "for epoch in range(10):\n",
    "  i = 0\n",
    "  for batch in train_dataset:\n",
    "      #print(input_ids.shape, position_ids.shape, token_ids.shape, label_ids.shape)\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
    "      input_ids = input_ids[0].reshape(1, -1)\n",
    "      label_ids = label_ids[0].reshape(1, -1)\n",
    "      \n",
    "      #모델 출력 생성 (out)\n",
    "      input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device).long()\n",
    "\n",
    "      out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, num_beams=5, num_return_sequences=1)\n",
    "      out = out[0][input_ids.size(-1)+1:-1].reshape(1, -1)\n",
    "\n",
    "      label_ids = label_ids[label_ids!=-1]\n",
    "      label_ids = torch.tensor(cut_seq_to_eos(label_ids.tolist())).reshape(1, -1).to(device)\n",
    "\n",
    "      #discriminator 입력 생성 (질문과 응답을 이어붙임)\n",
    "      real_input = torch.cat((input_ids, label_ids), dim=1).to(device)\n",
    "      fake_input = torch.cat((input_ids, out), dim=1).to(device)\n",
    "      #print(label_ids)\n",
    "\n",
    "      #discriminator 타겟 생성\n",
    "      tgt_real = torch.ones((1, 1)).to(device).float()\n",
    "      tgt_fake = torch.zeros((1, 1)).to(device).float()\n",
    "      \n",
    "      #real 역전파\n",
    "      output_real = D(real_input)\n",
    "      loss_real = criterion(output_real, tgt_real)\n",
    "      loss_real.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      #fake 역전파\n",
    "      output_fake = D(fake_input)\n",
    "      loss_fake = criterion(output_fake, tgt_fake)\n",
    "      loss_fake.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      out_real.append(output_real.cpu().item())\n",
    "      out_fake.append(output_fake.cpu().item())\n",
    "\n",
    "      if i % 100 == 0:\n",
    "        print(epoch, i, output_real, output_fake)\n",
    "        torch.save(D.state_dict(), 'D_lstm10_fc2.pkl')\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wtBAEkziWVF"
   },
   "source": [
    "## Discriminator 성능 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7sur_B9idxj"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out_real_test = []\n",
    "out_fake_test = []\n",
    " \n",
    "for batch in tqdm(test_dataset):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
    "    input_ids = input_ids[0].reshape(1, -1)\n",
    "    label_ids = label_ids[0].reshape(1, -1)\n",
    "      \n",
    "    #모델 출력 생성 (out)\n",
    "    input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device).long()\n",
    "\n",
    "    out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, num_beams=5, num_return_sequences=1)\n",
    "    out = out[0][input_ids.size(-1)+1:-1].reshape(1, -1)\n",
    "\n",
    "    label_ids = label_ids[label_ids!=-1]\n",
    "    label_ids = torch.tensor(cut_seq_to_eos(label_ids.tolist())).reshape(1, -1).to(device)\n",
    "\n",
    "    #discriminator 입력 생성 (질문과 응답을 이어붙임)\n",
    "    real_input = torch.cat((input_ids, label_ids), dim=1).to(device)\n",
    "    fake_input = torch.cat((input_ids, out), dim=1).to(device)\n",
    "\n",
    "    output_real = D(real_input)\n",
    "    output_fake = D(fake_input)\n",
    "\n",
    "    out_real_test.append(output_real.cpu().item())\n",
    "    out_fake_test.append(output_fake.cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "H0vvIDQ9hxPN"
   },
   "outputs": [],
   "source": [
    "out_real_test = np.array(out_real_test)\n",
    "out_fake_test = np.array(out_fake_test)\n",
    "\n",
    "np.save('out_real_test.npy', out_real_test)\n",
    "np.save('out_fake_test.npy', out_fake_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veElqKHXiB4C",
    "outputId": "a855cc88-caad-4da8-a67f-e32b22bdc540"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(out_real_test>out_fake_test) / len(out_real_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVUu0Mn6zkuc"
   },
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLF4rtLqzoU3",
    "outputId": "af6aa5c2-dc85-4ef5-917b-fb251fe5e884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:What's your favorite movie?\n",
      "Beam+Discriminator Output 1 :  The Big Lebowski. Score : 0.5781\n",
      "Beam+Discriminator Output 2 :  The Big Lebowski Score : 0.4769\n",
      "Beam+Discriminator Output 3 :  I don't watch a lot of movies, so I don't really have one. Score : 0.3901\n",
      "Beam+Discriminator Output 4 :  I don't really have a favorite. I like a lot of movies. Score : 0.361\n",
      "Beam+Discriminator Output 5 :  I don't have one! Score : 0.3121\n",
      "Beam+Discriminator Output 6 :  I don't really watch a lot of movies. Score : 0.3032\n",
      "Beam+Discriminator Output 7 :  Eternal Sunshine of the Spotless Mind! Score : 0.3009\n",
      "Beam+Discriminator Output 8 :  Blade Runner Score : 0.2968\n",
      "Beam+Discriminator Output 9 :  Star Wars Episode IV : A New Hope Score : 0.2957\n",
      "Beam+Discriminator Output 10 :  Pulp Fiction Score : 0.2936\n",
      "Beam+Discriminator Output 11 :  I don't watch a lot of movies. Score : 0.2852\n",
      "Beam+Discriminator Output 12 :  I don't really like movies. Score : 0.2842\n",
      "Beam+Discriminator Output 13 :  Space Jam Score : 0.2837\n",
      "Beam+Discriminator Output 14 :  Eternal Sunshine of the Spotless Mind Score : 0.2833\n",
      "Beam+Discriminator Output 15 :  I don't really have a favorite. Score : 0.2781\n",
      "Beam+Discriminator Output 16 :  I don't have a favorite. Score : 0.2759\n",
      "Beam+Discriminator Output 17 :  Star Wars Episode IV : A New Hope. Score : 0.2754\n",
      "Beam+Discriminator Output 18 :  I don't really watch movies. Score : 0.2697\n",
      "Beam+Discriminator Output 19 :  I don't have a favorite movie. Score : 0.2692\n",
      "Beam+Discriminator Output 20 :  Eternal Sunshine of the Spotless Mind. Score : 0.2674\n",
      "Beam+Discriminator Output 21 :  I don't watch movies Score : 0.2659\n",
      "Beam+Discriminator Output 22 :  Pulp Fiction. Score : 0.2645\n",
      "Beam+Discriminator Output 23 :  I don't really watch movies Score : 0.2616\n",
      "Beam+Discriminator Output 24 :  Harry Potter and the Chamber of Secrets Score : 0.2611\n",
      "Beam+Discriminator Output 25 :  I don't like movies. Score : 0.2554\n",
      "Beam+Discriminator Output 26 :  The Departed Score : 0.2534\n",
      "Beam+Discriminator Output 27 :  Shawshank redemption. Score : 0.2513\n",
      "Beam+Discriminator Output 28 :  I don't really have one Score : 0.2505\n",
      "Beam+Discriminator Output 29 :  The Prestige Score : 0.2499\n",
      "Beam+Discriminator Output 30 :  I really don't have one. Score : 0.2497\n",
      "Beam+Discriminator Output 31 :  Harry Potter and the Methods of Rationality. Score : 0.2494\n",
      "Beam+Discriminator Output 32 :  I don't really have a favorite movie. Score : 0.2493\n",
      "Beam+Discriminator Output 33 :  Shawshank Redemption! Score : 0.2463\n",
      "Beam+Discriminator Output 34 :  Shawshank Redemption Score : 0.2456\n",
      "Beam+Discriminator Output 35 :  Harry Potter and the Chamber of Secrets. Score : 0.244\n",
      "Beam+Discriminator Output 36 :  Harry Potter and the Methods of Rationality Score : 0.2438\n",
      "Beam+Discriminator Output 37 :  I don't have one. Score : 0.2426\n",
      "Beam+Discriminator Output 38 :  I don't really have one. Score : 0.2424\n",
      "Beam+Discriminator Output 39 :  Shawshank redemption Score : 0.2419\n",
      "Beam+Discriminator Output 40 :  What's yours? Score : 0.2416\n",
      "Beam+Discriminator Output 41 :  The Departed! Score : 0.2358\n",
      "Beam+Discriminator Output 42 :  I don't watch movies. Score : 0.2329\n",
      "Beam+Discriminator Output 43 :  The Dark Knight Rises Score : 0.2252\n",
      "Beam+Discriminator Output 44 :  I don't have one Score : 0.221\n",
      "Beam+Discriminator Output 45 :  Shawshank Redemption. Score : 0.2156\n",
      "Beam+Discriminator Output 46 :  The Dark Knight Rises. Score : 0.2148\n",
      "Beam+Discriminator Output 47 :  The Prestige. Score : 0.214\n",
      "Beam+Discriminator Output 48 :  Forrest Gump Score : 0.2106\n",
      "Beam+Discriminator Output 49 :  Forrest Gump. Score : 0.2063\n",
      "Beam+Discriminator Output 50 :  The Departed. Score : 0.2052\n",
      "Greedy Output :  I don't really watch movies.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "model.eval()\n",
    "input_ids = enc.encode(input(\">> User:\") + enc.eos_token, return_tensors='pt').to(device)\n",
    "#input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device)\n",
    "    \n",
    "#Beam search 사용해 하나의 Source 문장마다 50개의 응답 생성\n",
    "out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, num_beams=50, num_return_sequences=50, top_k=200, temperature=0.9, no_repeat_ngram_size=3)\n",
    "out_greedy = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID)\n",
    "out_greedy = out_greedy[0][out_greedy[0]!=-1][input_ids.size(-1):-1]\n",
    "input_ids = input_ids[0][:-1]\n",
    "\n",
    "#print(\"Input : \", enc.decode(input_ids))\n",
    "dis_score = np.array([])\n",
    "for j in range(50):\n",
    "    output = out[j]\n",
    "    output = output[output!=-1][input_ids.size(-1)+1:-1]\n",
    "    dis_score = np.append(dis_score, D(output.reshape(1, -1)).item())\n",
    "\n",
    "rank = np.argsort(dis_score)[::-1]\n",
    "for k, r in enumerate(rank):\n",
    "    output = out[r]\n",
    "    output = output[output!=-1][input_ids.size(-1)+1:-1]\n",
    "    print(\"Beam+Discriminator Output {} : \".format(k+1), enc.decode(output), \"Score : {:.4}\".format(dis_score[r]))z\n",
    "\n",
    "print(\"Greedy Output : \", enc.decode(out_greedy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "al6ecr6qJEBQ"
   },
   "source": [
    "## Benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XECftD1r4Yx"
   },
   "source": [
    "### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgNtghVIJFUb"
   },
   "outputs": [],
   "source": [
    "#BLEU Score 계산산\n",
    "from torchmetrics import BLEUScore\n",
    "metric = BLEUScore()\n",
    "model.eval()\n",
    "out_real_test = []\n",
    "out_fake_test = []\n",
    "score_sum = 0\n",
    "\n",
    "for batch in tqdm(test_dataset):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
    "    input_ids = input_ids[0].reshape(1, -1)\n",
    "    label_ids = label_ids[0].reshape(1, -1)\n",
    "      \n",
    "    #모델 출력 생성 (out)\n",
    "    input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device).long()\n",
    "\n",
    "    out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, num_beams=50, num_return_sequences=50, top_k=200, temperature=0.9, no_repeat_ngram_size=3)\n",
    "\n",
    "    label_ids = label_ids[label_ids!=-1]\n",
    "    label_ids = torch.tensor(cut_seq_to_eos(label_ids.tolist())).reshape(1, -1).numpy()\n",
    "    \n",
    "    dis_score = np.array([])\n",
    "    for j in range(50):\n",
    "        output = out[j]\n",
    "        output = output[output!=-1][input_ids.size(-1)+1:-1]\n",
    "        dis_score = np.append(dis_score, D(output.reshape(1, -1)).item())\n",
    "    rank = np.argsort(dis_score)[::-1]\n",
    "    output = out[rank[0]]\n",
    "    output = output[output!=-1][input_ids.size(-1):-1]\n",
    "\n",
    "    label = []\n",
    "    generated = []\n",
    "    for tok in label_ids[0]:\n",
    "        label.append(enc.decode(tok))\n",
    "    for tok in output:\n",
    "        generated.append(enc.decode(tok))\n",
    "    score = metric(label, generated)\n",
    "    score_sum += score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcRtuhVnr69Q"
   },
   "source": [
    "### Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11eQ4tmHSrAv",
    "outputId": "7872be07-6563-44c2-8438-9d0daa89368b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.8097373165958293,\n",
       "  3.938952636841678,\n",
       "  3.8874845719179723,\n",
       "  3.5218412405832353],\n",
       " [0.24175824175797608,\n",
       "  0.8082191780810846,\n",
       "  0.9272727272710413,\n",
       "  0.9459459459433893])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diversity 평가\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def prepare_for_bleu(sentence):\n",
    "    sent = [x for x in sentence if x!=0]\n",
    "    while len(sent)<4:\n",
    "        sent.append('0')\n",
    "    sent = ' '.join([str(x) for x in sent])\n",
    "    return sent   \n",
    "\n",
    "def cal_entropy(generated):\n",
    "    # print 'in BLEU score calculation'\n",
    "    # the maximum is bigram, so assign the weight into 2 half.\n",
    "    etp_score = [0.0, 0.0, 0.0, 0.0]\n",
    "    div_score = [0.0, 0.0, 0.0, 0.0]\n",
    "    counter = [defaultdict(int), defaultdict(int), defaultdict(int), defaultdict(int)]\n",
    "    for gg in generated:\n",
    "        g = gg.rstrip('2').split()\n",
    "        for n in range(4):\n",
    "            for idx in range(len(g)-n):\n",
    "                ngram = ' '.join(g[idx:idx+n+1])\n",
    "                counter[n][ngram] += 1\n",
    "    for n in range(4):\n",
    "        total = sum(counter[n].values()) +1e-10\n",
    "        for v in counter[n].values():\n",
    "            etp_score[n] += - (v+0.0) /total * (np.log(v+0.0) - np.log(total))\n",
    "        div_score[n] = (len(counter[n].values())+0.0) /total\n",
    "    return etp_score, div_score\n",
    "\n",
    "cal_entropy([prepare_for_bleu(s) for s in  res_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ac-JnscTb21O",
    "outputId": "2cecc023-ead6-4095-960d-19f70f462655"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [36:56<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "etp_scores = []\n",
    "div_scores = []\n",
    "\n",
    "for batch in tqdm(test_dataset):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
    "    input_ids = input_ids[0].reshape(1, -1)\n",
    "    label_ids = label_ids[0].reshape(1, -1)\n",
    "      \n",
    "    #모델 출력 생성 (out)\n",
    "    input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device).long()\n",
    "\n",
    "    out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, num_beams=50, num_return_sequences=50, top_k=200, temperature=0.9, no_repeat_ngram_size=3)\n",
    "\n",
    "    label_ids = label_ids[label_ids!=-1]\n",
    "    label_ids = torch.tensor(cut_seq_to_eos(label_ids.tolist())).reshape(1, -1).numpy()\n",
    "    \n",
    "    dis_score = np.array([])\n",
    "    for j in range(50):\n",
    "        output = out[j]\n",
    "        output = output[output!=-1][input_ids.size(-1)+1:-1]\n",
    "        if len(output) > 0:\n",
    "            dis_score = np.append(dis_score, D(output.reshape(1, -1)).item())\n",
    "    rank = np.argsort(dis_score)[::-1]\n",
    "    output = out[rank[0]]\n",
    "    output = output[output!=-1][input_ids.size(-1):-1]\n",
    "\n",
    "    label = []\n",
    "    generated = []\n",
    "    for tok in label_ids[0]:\n",
    "        label.append(enc.decode(tok))\n",
    "    for tok in output:\n",
    "        generated.append(enc.decode(tok))\n",
    "    \n",
    "    etp, div = cal_entropy([prepare_for_bleu(s) for s in generated])\n",
    "    etp_scores.append(etp)\n",
    "    div_scores.append(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocK4bp61ogHP",
    "outputId": "2381a763-dffc-451a-f99d-3a9ee835be88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ETP Scores of Beam Search + Discriminator method\n",
      "[2.60093481 3.16976956 3.09910681 2.53060631]\n",
      "\n",
      "\n",
      "Mean DIV Scores of Beam Search + Discriminator method\n",
      "[0.373178   0.7281995  0.87249993 0.95076622]\n"
     ]
    }
   ],
   "source": [
    "etp_scores, div_scores = np.array(etp_scores), np.array(div_scores)\n",
    "print(\"Mean ETP Scores of Beam Search + Discriminator method\")\n",
    "print(etp_scores.mean(axis=0))\n",
    "print(\"\\n\")\n",
    "print(\"Mean DIV Scores of Beam Search + Discriminator method\")\n",
    "print(div_scores.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHErVHcupCHj",
    "outputId": "756342ba-f06b-4b90-fdaa-02072027fe5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:18<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "etp_scores_greedy = []\n",
    "div_scores_greedy = []\n",
    "\n",
    "for batch in tqdm(test_dataset):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
    "    input_ids = input_ids[0].reshape(1, -1)\n",
    "    label_ids = label_ids[0].reshape(1, -1)\n",
    "      \n",
    "    #모델 출력 생성 (out)\n",
    "    input_ids = torch.cat((torch.tensor(cut_seq_to_eos(input_ids[0].tolist())).reshape(1, -1), torch.tensor([[EOS_ID]])), dim=1).to(device).long()\n",
    "\n",
    "    out = model.generate(input_ids, pad_token_id=-1, max_length=1000, eos_token_id=EOS_ID, top_k=200, temperature=0.9, no_repeat_ngram_size=3)\n",
    "\n",
    "    label_ids = label_ids[label_ids!=-1]\n",
    "    label_ids = torch.tensor(cut_seq_to_eos(label_ids.tolist())).reshape(1, -1).numpy()\n",
    "    \n",
    "    output = out[0]\n",
    "    output = output[output!=-1][input_ids.size(-1)+1:-1]\n",
    "\n",
    "    rank = np.argsort(dis_score)[::-1]\n",
    "    output = out[rank[0]]\n",
    "    output = output[output!=-1][input_ids.size(-1):-1]\n",
    "\n",
    "    label = []\n",
    "    generated = []\n",
    "    for tok in label_ids[0]:\n",
    "        label.append(enc.decode(tok))\n",
    "    for tok in output:\n",
    "        generated.append(enc.decode(tok))\n",
    "    \n",
    "    etp, div = cal_entropy([prepare_for_bleu(s) for s in generated])\n",
    "    etp_scores_greedy.append(etp)\n",
    "    div_scores_greedy.append(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdwSTCOgquBq",
    "outputId": "7ce3a56a-2b09-4101-d339-9e1db916c61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ETP Scores of Greedy method\n",
      "[2.52981549 3.04879787 2.97176381 2.37611847]\n",
      "\n",
      "\n",
      "Mean DIV Scores of Greedy method\n",
      "[0.40057563 0.73379508 0.87307077 0.95227216]\n"
     ]
    }
   ],
   "source": [
    "etp_scores_greedy, div_scores_greedy = np.array(etp_scores_greedy), np.array(div_scores_greedy)\n",
    "print(\"Mean ETP Scores of Greedy method\")\n",
    "print(etp_scores_greedy.mean(axis=0))\n",
    "print(\"\\n\")\n",
    "print(\"Mean DIV Scores of Greedy method\")\n",
    "print(div_scores_greedy.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02f1d7778a3b4c6b935e6894ecbb286a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0825bb79bb4e4a3ca6fc262d85115698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87adac30280342f7a8d1352f12c316f7",
      "placeholder": "​",
      "style": "IPY_MODEL_29bd60600a6f45bf877659726b6a45a5",
      "value": " 642/642 [00:00&lt;00:00, 34.3kB/s]"
     }
    },
    "09db7d7a73124f01a16ec74e2d682a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4a00089edd7418698ecae796839d5b8",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b1423dbce724d83b0a0284b965f9b59",
      "value": 1042301
     }
    },
    "0c54771fb9f04b218f5ea1e772b11191": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d01351ba01a48b0b37f7ab574d8c6d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "135d56637ce94f56b92133d59cc8f4f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "188e723f8e1a4ebdbe0d279db0ae90f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ade84462c704497a9cb7851b4469ac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6771f58c7e864c9082c508e63b6bd95f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b05cfbc37b4f440f910ec62ee3289d77",
      "value": 456318
     }
    },
    "1b1423dbce724d83b0a0284b965f9b59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e15765b8bc540f3873b11ce25cec251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2194c574fd35495bbed06e82b1a013ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d01351ba01a48b0b37f7ab574d8c6d8",
      "placeholder": "​",
      "style": "IPY_MODEL_188e723f8e1a4ebdbe0d279db0ae90f1",
      "value": "Downloading: 100%"
     }
    },
    "21aa0ea9e1cd4579aaeb1db66c55e323": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2292aa36157348f792951a5b55a0db73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2702c4867d7b439b92c0eedae122ddf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cb312662ec4445bb9ac3e51af6af70c",
      "placeholder": "​",
      "style": "IPY_MODEL_da4e4ca6d09d427a9fe7ef93756e3bc9",
      "value": "Downloading: 100%"
     }
    },
    "29bd60600a6f45bf877659726b6a45a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b0e99810686444292a9d433123427d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f1173e1260440799d72e849ac0d2500",
      "max": 642,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_472c0527457b42aa94909ce527034ba7",
      "value": 642
     }
    },
    "2bceafb970d54462b2688147f59ebbc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d0feb2c9dd4e5e9b3ee82db3b97590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32b8245357c44077be92bf0bf234d100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34749134936c4747903244810dfb88cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38945aa937fa41ab81161ed6c2ee30ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a5808be83d742aab60a2b259865238e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e15765b8bc540f3873b11ce25cec251",
      "placeholder": "​",
      "style": "IPY_MODEL_f782225cde864538b319872c54da8796",
      "value": " 1.04M/1.04M [00:01&lt;00:00, 962kB/s]"
     }
    },
    "472c0527457b42aa94909ce527034ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "47c04e98be0a4c5a8a384364d75f21da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5273c39161b646878eb5a3efc39afc44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6c6aa95f1af40a68325bac7b21b0aea",
       "IPY_MODEL_f830d977c85144be9be2c831fa45f928",
       "IPY_MODEL_ce8bb417e4334b94ba3f873ee57878a6"
      ],
      "layout": "IPY_MODEL_9f2ffe81371c411883a82928ff24c673"
     }
    },
    "54e65fa9345d405a839e6e99af6f51d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6771f58c7e864c9082c508e63b6bd95f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "694ca3557bce4cb9abd3494df5e3fccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6ea59210ee5d400a9b0828a62903c143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bceafb970d54462b2688147f59ebbc5",
      "placeholder": "​",
      "style": "IPY_MODEL_31d0feb2c9dd4e5e9b3ee82db3b97590",
      "value": " 456k/456k [00:01&lt;00:00, 459kB/s]"
     }
    },
    "6f1173e1260440799d72e849ac0d2500": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7115aa1a40c042b4a210707c339b067c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cb312662ec4445bb9ac3e51af6af70c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83e856a3a02641a09c4627b3e59e3128": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2194c574fd35495bbed06e82b1a013ce",
       "IPY_MODEL_09db7d7a73124f01a16ec74e2d682a43",
       "IPY_MODEL_3a5808be83d742aab60a2b259865238e"
      ],
      "layout": "IPY_MODEL_38945aa937fa41ab81161ed6c2ee30ea"
     }
    },
    "87adac30280342f7a8d1352f12c316f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f38a84fcd74cde9b0089fec28a8c0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2702c4867d7b439b92c0eedae122ddf8",
       "IPY_MODEL_9492632cbac54938a9a833dcf7245919",
       "IPY_MODEL_c41a460b32464439986ceff8c56c226e"
      ],
      "layout": "IPY_MODEL_a3f1d255d33f45aab0e65b0c7ce31b7b"
     }
    },
    "9492632cbac54938a9a833dcf7245919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8e139c2e3254dc7a2478555a60600d6",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_694ca3557bce4cb9abd3494df5e3fccd",
      "value": 26
     }
    },
    "97185e23041048ed89ef72155ef96994": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca0ac0dc040543edb8b8337ffa81cebc",
       "IPY_MODEL_1ade84462c704497a9cb7851b4469ac2",
       "IPY_MODEL_6ea59210ee5d400a9b0828a62903c143"
      ],
      "layout": "IPY_MODEL_a950f1757afa422f9128abcc885c82d5"
     }
    },
    "99bafd08439d41d6ac192045d1f31fd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f2ffe81371c411883a82928ff24c673": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3f1d255d33f45aab0e65b0c7ce31b7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6c6aa95f1af40a68325bac7b21b0aea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21aa0ea9e1cd4579aaeb1db66c55e323",
      "placeholder": "​",
      "style": "IPY_MODEL_135d56637ce94f56b92133d59cc8f4f9",
      "value": "Downloading: 100%"
     }
    },
    "a950f1757afa422f9128abcc885c82d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b05cfbc37b4f440f910ec62ee3289d77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c41a460b32464439986ceff8c56c226e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99bafd08439d41d6ac192045d1f31fd8",
      "placeholder": "​",
      "style": "IPY_MODEL_f7c8ebd9eacd486d98b78678d0b6618c",
      "value": " 26.0/26.0 [00:00&lt;00:00, 1.46kB/s]"
     }
    },
    "c4a00089edd7418698ecae796839d5b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8ef5390aaf9477d9e7194e1d5365e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d975e3a953eb4aea837e9f45d3535ac7",
       "IPY_MODEL_2b0e99810686444292a9d433123427d0",
       "IPY_MODEL_0825bb79bb4e4a3ca6fc262d85115698"
      ],
      "layout": "IPY_MODEL_02f1d7778a3b4c6b935e6894ecbb286a"
     }
    },
    "c92bb8b9d5aa4aeaac2950cb9ccf73ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0ac0dc040543edb8b8337ffa81cebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2292aa36157348f792951a5b55a0db73",
      "placeholder": "​",
      "style": "IPY_MODEL_34749134936c4747903244810dfb88cd",
      "value": "Downloading: 100%"
     }
    },
    "ce8bb417e4334b94ba3f873ee57878a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c54771fb9f04b218f5ea1e772b11191",
      "placeholder": "​",
      "style": "IPY_MODEL_7115aa1a40c042b4a210707c339b067c",
      "value": " 863M/863M [00:54&lt;00:00, 16.8MB/s]"
     }
    },
    "d8e139c2e3254dc7a2478555a60600d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d975e3a953eb4aea837e9f45d3535ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c92bb8b9d5aa4aeaac2950cb9ccf73ff",
      "placeholder": "​",
      "style": "IPY_MODEL_54e65fa9345d405a839e6e99af6f51d8",
      "value": "Downloading: 100%"
     }
    },
    "da4e4ca6d09d427a9fe7ef93756e3bc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f782225cde864538b319872c54da8796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7c8ebd9eacd486d98b78678d0b6618c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f830d977c85144be9be2c831fa45f928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47c04e98be0a4c5a8a384364d75f21da",
      "max": 862955157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32b8245357c44077be92bf0bf234d100",
      "value": 862955157
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
